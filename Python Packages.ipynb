{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Machine Learning Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning is a collection of algorithms and techniques used to create computational systems that learn from data in order to make predictions and inferences.\n",
    "\n",
    "AI Process Loop :\n",
    "###### Observe – identify patterns using the data\n",
    "###### Plan – find all possible solutions\n",
    "###### Optimize – find optimal solution from the list of possible solutions\n",
    "###### Action – execute the optimal solution\n",
    "###### Learn and Adapt – is the result giving expected result, if no adapt\n",
    "\n",
    "\n",
    "ML Process Loop : There are six major phases :\n",
    "###### Business understanding\n",
    "###### Data understanding\n",
    "###### Data preparation\n",
    "######  Modeling\n",
    "###### Evaluation\n",
    "###### Deployment\n",
    "\n",
    "There is a rich number of open source libraries available to facilitate practical machine learning. These are mainly known as scientific Python libraries and are generally put to use when performing elementary machine learning tasks. At a high level we can divide these libraries into data analysis and core machine learning libraries based on their usage/purpose.\n",
    "Data analysis packages:\n",
    "These are the sets of packages that provide us the mathematic and scientific functionalities that are essential to perform data preprocessing and transformation.\n",
    "Core Machine learning packages:\n",
    "These are the set of packages that provide us with all the necessary machine learning algorithms and functionalities that can be applied on a given dataset to extract the patterns.\n",
    "\n",
    "1.1: Data Analysis Packages\n",
    "\n",
    "There are four key packages that are most widely used for data analysis.\n",
    "1.1.1: NumPy\n",
    "1.1.2: SciPy\n",
    "1.1.3: Matplotlib\n",
    "1.1.4: Pandas¶ \n",
    "1.1.5 : NumPy\n",
    "\n",
    "NumPy is the core library for scientific computing in Python. It provides a highperformance multidimensional array object, and tools for working with these array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code for initializing NumPy array\n",
    "import numpy as np\n",
    "# Create a rank 1 array\n",
    "a = np.array([0, 1, 2])\n",
    "print(type(a))\n",
    "# this will print the dimension of the array\n",
    "print(a.shape)\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "print(a[2])\n",
    "# Change an element of the array\n",
    "a[0] = 5\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a rank 2 array\n",
    "b = np.array([[0,1,2],[3,4,5]])\n",
    "print(b.shape)\n",
    "print(b)\n",
    "print(b[0, 0], b[0, 1], b[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 array of all zeros\n",
    "a = np.zeros((3,3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 array of all ones\n",
    "b = np.ones((2,2))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 constant array\n",
    "c = np.full((3,3), 7)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 array filled with random values\n",
    "d = np.random.random((3,3))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 identity matrix\n",
    "e = np.eye(3)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to array\n",
    "f = np.array([2, 3, 1, 0])\n",
    "print(f)\n",
    "#print([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arange() will create arrays with regularly incrementing values\n",
    "g = np.arange(2,10)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note mix of tuple and lists\n",
    "h = np.array([[0,1,2.0],[0,0,0],(1+1j,3.,2.)])\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of range with float data type\n",
    "i = np.arange(1, 8, dtype=np.float)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linspace() will create arrays with a specified number of items which are\n",
    "# spaced equally between the specified beginning and end values\n",
    "j = np.linspace(2., 4., 5)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices() will create a set of arrays stacked as a one-higher\n",
    "# dimensioned array, one per dimension with each representing variation\n",
    "# in that dimension\n",
    "k = np.indices((3,3))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NumPy datatypes\n",
    "# Let numpy choose the datatype\n",
    "x = np.array([0, 1])\n",
    "y = np.array([2.0, 3.0])\n",
    "# Force a particular datatype\n",
    "z = np.array([5, 6], dtype=np.int64)\n",
    "print(x.dtype, y.dtype, z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic slicing : The basic slice syntax is i: j: k, \n",
    "# where i is the starting index,j is the stopping index,\n",
    "# and k is the step and k is not equal to 0.\n",
    "x = np.array([5, 6, 7, 8, 9])\n",
    "print(x[1:7:2])\n",
    "print(x[-2:5])\n",
    "print(x[-1:1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boolean array indexing\n",
    "a=np.array([[1,2], [3, 4], [5, 6]])\n",
    "# Find the elements of a that are bigger than 2\n",
    "print (a > 2)\n",
    "# to get the actual value\n",
    "print (a[a > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=np.array([[1,2],[3,4],[5,6]])\n",
    "y=np.array([[7,8],[9,10],[11,12]])\n",
    "# Elementwise sum; both produce the array\n",
    "print(x+y)\n",
    "print(np.add(x, y))\n",
    "# Elementwise difference; both produce the array\n",
    "print(x-y)\n",
    "print(np.subtract(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementwise product; both produce the array\n",
    "print(x*y)\n",
    "print(np.multiply(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x/y)\n",
    "print(np.divide(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([9,10])\n",
    "b=np.array([11, 12])\n",
    "# Inner product of vectors; both produce 219\n",
    "print(a.dot(b))\n",
    "print(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix / vector product; both produce the rank 1 array [29 67]\n",
    "x=np.array([[1,2],[3,4]])\n",
    "print(x.dot(a))\n",
    "print(np.dot(x, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix / matrix product; both produce the rank 2 array\n",
    "y=np.array([[5,6],[7,8]])\n",
    "print(x.dot(y))\n",
    "print(np.dot(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum function\n",
    "x=np.array([[1,2],[3,4]])\n",
    "# Compute sum of all elements\n",
    "print (np.sum(x))\n",
    "# Compute sum of each column\n",
    "print (np.sum(x, axis=0))\n",
    "# Compute sum of each row\n",
    "print (np.sum(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transpose function\n",
    "x=np.array([[1,2], [3,4]])\n",
    "print(x)\n",
    "print(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that taking the transpose of a rank 1 array does nothing:\n",
    "v=np.array([1,2,3])\n",
    "print(v)\n",
    "print(v.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting : Broadcasting enables arithmetic operations to be performed between different shaped arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting using NumPy\n",
    "a = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "v = np.array([1, 0, 1])\n",
    "# Add v to each row of a using broadcasting\n",
    "b = a + v\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector to each column of a matrix\n",
    "# x has shape (2, 3) and w has shape (2,).\n",
    "# If we transpose x then it has shape (3, 2) and can be broadcast\n",
    "# against w to yield a result of shape (3, 2); transposing this result\n",
    "# yields the final result of shape (2, 3) which is the matrix x with\n",
    "# the vector w added to each column\n",
    "x=np.array([[1,2,1], [3,4,1]])\n",
    "print(\"X.T:\\n\",x.T)\n",
    "w= np.array([1,1])\n",
    "print(\"W:\\n\",w)\n",
    "\n",
    "print(\"Final :\\n\",(x.T + w).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply a matrix by a constant:\n",
    "# x has shape (2, 3). Numpy treats scalars as arrays of shape ();\n",
    "# these can be broadcast together to shape (2, 3)\n",
    "print(x * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas are an open source Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. Pandas are well suited for tabular data with heterogeneously typed columns, as in an SQL table or Excel spreadsheet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Structures:\n",
    "Pandas introduces two new data structures to Python [ both of which are built on top of NumPy (this means it’s fast).]\n",
    "\n",
    "1.Series \n",
    "2.DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Series : This is a one-dimensional object similar to column in a spreadsheet or SQL table. By default each item will be assigned an index label from 0 to N.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a pandas series\n",
    "# creating a series by passing a list of values, and a custom index label.\n",
    "#Note that the labeled index reference for each row and it can have\n",
    "#duplicate values\n",
    "s = pd.Series([1,2,3,np.nan,5,6], index=['A','B','C','D','E','F'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.DataFrame : It is a two-dimensional object similar to a spreadsheet or an SQL table. This is the most commonly used pandas object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a pandas dataframe\n",
    "data = {'Gender': ['F', 'M', 'M'],'Emp_ID': ['E01', 'E02',\n",
    "'E03'], 'Age': [25, 27, 25]}\n",
    "# We want the order the columns, so lets specify in columns parameter\n",
    "df = pd.DataFrame(data, columns=['Emp_ID','Gender', 'Age'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading / writing data from csv, text, Excel\n",
    "\n",
    "# Reading frome csv\n",
    "df=pd.read_csv('C:/Users/thyagaragu/Desktop/Data/PF/CSV/CHS2.csv') \n",
    "print(\"READ CSV:\\n\",df)\n",
    "#Writing to csv\n",
    "df.to_csv('C:/Users/thyagaragu/Desktop/Data/PF/CSV/CHS0.csv', index=False)\n",
    "print(\"WRITE CSV:\\n\",df)\n",
    "\n",
    "# Reading from text Files \n",
    "df=pd.read_csv('C:/Users/thyagaragu/Desktop/Data/PF/TEXT/ex.txt', sep='\\t') # from text file\n",
    "print(\"READ TXT:\\n\",df)\n",
    "#Writing to text Files\n",
    "df.to_csv('C:/Users/thyagaragu/Desktop/Data/PF/TEXT/ex0.txt', sep='\\t', index=False)\n",
    "print(\"WRITE TXT:\\n\",df)\n",
    "\n",
    "#Reading from Excel File \n",
    "df=pd.read_excel('C:/Users/thyagaragu/Desktop/Data/PF/EXCEL/Heart_Patient.xlsx','Sheet1') # from Excel\n",
    "print(\"READ EXCEL:\\n\",df)\n",
    "\n",
    "#Writing to Excel File\n",
    "df.to_excel('C:/Users/thyagaragu/Desktop/Data/PF/EXCEL/Heart_Patient0.xlsx',sheet_name='Sheet1', index = False)\n",
    "print(\"WRITE EXCEL:\\n\",df)\n",
    "\n",
    "# reading from multiple sheets of same Excel into different dataframes\n",
    "xlsx = pd.ExcelFile('C:/Users/thyagaragu/Desktop/Data/PF/EXCEL/Heart_Patient.xlsx')\n",
    "sheet1_df = pd.read_excel(xlsx, 'Sheet1')\n",
    "print(\"EXCEL SHEET1:\\n\",sheet1_df)\n",
    "sheet2_df = pd.read_excel(xlsx, 'Sheet2')\n",
    "print(\"EXCEL SHEET2:\\n\",sheet2_df)\n",
    "\n",
    "# writing\n",
    "# index = False parameter will not write the index values, default is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data From URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV from URL using NumPy\n",
    "from numpy import loadtxt\n",
    "from urllib.request import urlopen\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'\n",
    "raw_data = pd.read_csv(urlopen(url))\n",
    "print(raw_data.shape)\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data From Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "iris=load_iris()\n",
    "#iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data)\n",
    "X.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n",
    "#X.head()\n",
    "print(\"Shape:\\n\",X.shape)\n",
    "print(\"Head:\\n\",X.head(5))\n",
    "print(\"Tail:\\n\",X.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Statistics Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has some built-in functions to help us to get better understanding of data using basic statistical summary methods describe()- will returns the quick stats such as count, mean, std (standard deviation), min, first quartile, median, third quartile, max on each column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cov() - Covariance indicates how two variables are related. A positive¶ \n",
    "\n",
    "covariance means the variables are positively related, while a negative covariance means the variables are inversely related. Drawback of covariance is that it does not tell you the degree of positive or negative relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### corr() - Correlation is another way to determine how two variables are related. In addition to telling you whether variables are positively or inversely related, correlation also tells you the degree to which the variables tend to move together.\n",
    "\n",
    "When you say that two items correlate, you are saying that the change in one item effects a change in another item. You will always talk about correlation as a range between -1 and 1. In the below example code, petal length is 87% positively related to sepal length that means a change in petal length results in a positive 87% change to sepal lenth and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping\n",
    "\n",
    "Grouping involves one or more of the following steps:\n",
    "\n",
    "• Splitting the data into groups based on some criteria,\n",
    "• Applying a function to each group independently,¶ \n",
    "• Combining the results into a data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping operation\n",
    "df = pd.DataFrame({'Name' : ['jack', 'jane', 'jack', 'jane', 'jack', 'jane',\n",
    "'jack', 'jane'],'State' : ['SFO', 'SFO', 'NYK', 'CA', 'NYK', 'NYK','SFO', 'CA'],\n",
    "'Grade':['A','A','B','A','C','B','C','A'],\n",
    "'Age' : np.random.uniform(24, 50, size=8),\n",
    "'Salary' : np.random.uniform(3000, 5000, size=8),})\n",
    "# Note that the columns are ordered automatically in their alphabetic order\n",
    "print(df)\n",
    "# for custom order please use below code\n",
    "# df = pd.DataFrame(data, columns = ['Name', 'State', 'Age','Salary'])\n",
    "# Find max age and salary by Name / State\n",
    "# with groupby, we can use all aggregate functions such as min, max, mean,\n",
    "#count, cumsum\n",
    "df.groupby(['Name','State']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is a numerical mathematics extension NumPy and a great package to view or present data in a pictorial or graphical format. It enables analysts and decision makers to see analytics presented visually, so they can grasp difficult concepts or identify new patterns. There are two broad ways of using pyplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Global Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common and easy approach is by using global functions to build and display a global figure using matplotlib as a global state machine. Some of the most commonly used charts.\n",
    "\n",
    "plt.scatter – makes a scatter plot\n",
    "plt.bar – creates a bar chart\n",
    "plt.boxplot – makes a box and whisker plot\n",
    "plt.hist – makes a histogram\n",
    "plt.plot – creates a line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating plot on variables\n",
    "# simple bar and scatter plot\n",
    "\n",
    "x = np.arange(5) # assume there are 5 students\n",
    "y = (20, 35, 30, 35, 27) # their test scores\n",
    "plt.bar(x,y) # Bar plot\n",
    "\n",
    "# need to close the figure using show() or close(), if not closed\n",
    "# any follow plot commands will use same figure.\n",
    "\n",
    "plt.show() # Try commenting this an run\n",
    "plt.scatter(x,y) # scatter plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample data\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n",
    "print(\"Histogram:\\n\")\n",
    "df.hist()# Histogram\n",
    "plt.show()\n",
    "print(\"Line Graph:\\n\")\n",
    "df.plot() # Line Graph\n",
    "plt.show()\n",
    "print(\"Box Plot:\\n\")\n",
    "df.boxplot() # Box plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customize labels\n",
    "\n",
    "# generate sample data\n",
    "x = np.linspace(0, 20, 1000) #100 evenly-spaced values from 0 to 50\n",
    "y = np.sin(x)\n",
    "\n",
    "# customize axis labels\n",
    "plt.plot(x, y, label = 'Sample Label')\n",
    "plt.title('Sample Plot Title') # chart title\n",
    "plt.xlabel('x axis label') # x axis title\n",
    "plt.ylabel('y axis label') # y axis title\n",
    "plt.grid(True) # show gridlines\n",
    "\n",
    "# add footnote\n",
    "plt.figtext(0.5, 0.01, 'Fig1: Sinusoidal', ha='right', va='bottom')\n",
    "\n",
    "# add legend, location pick the best automatically\n",
    "plt.legend(loc='best', framealpha=0.5, prop={'size':'small'})\n",
    "\n",
    "# tight_layout() can take keyword arguments of pad, w_pad and h_pad.\n",
    "# these control the extra padding around the figure border and between\n",
    "#subplots. The pads are specified in fraction of fontsize.\n",
    "plt.tight_layout(pad=1)\n",
    "\n",
    "# Saving chart to a file\n",
    "#plt.savefig('filename.png')\n",
    "#plt.close() \n",
    "# Close the current window to allow new plot creation on\n",
    "#separate window / axis, alternatively we can use show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "import seaborn\n",
    "print('seaborn: {}'.format(seaborn.__version__))\n",
    "import pgmpy\n",
    "print('pgmpy: {}'.format(pgmpy.__name__))\n",
    "import urllib\n",
    "print('urlib: {}'.format(urllib.__name__))\n",
    "import csv\n",
    "print('csv: {}'.format(csv.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy, pronounced as Sigh Pi, is a scientific python open source, distributed under the BSD licensed library to perform Mathematical, Scientific and Engineering Computations. The SciPy library depends on NumPy, which provides convenient and fast N-dimensional array manipulation. The SciPy library is built to work with NumPy arrays and provides many user-friendly and efficient numerical practices such as routines for numerical integration and optimization. Together, they run on all popular operating systems, are quick to install and are free of charge. NumPy and SciPy are easy to use, but powerful enough to depend on by some of the world's leading scientists and engineers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.linspace(1., 4., 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Means Implementation in SciPy\n",
    "from scipy.cluster.vq import kmeans,vq,whiten\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "\n",
    "# data generation with three features\n",
    "data = vstack((rand(100,3) + array([.5,.5,.5]),rand(100,3)))\n",
    "#print(data)\n",
    "# whitening of data for normalizing\n",
    "data = whiten(data)\n",
    "#print(data)\n",
    "# computing K-Means with K = 3 (2 clusters)\n",
    "centroids,_ = kmeans(data,3)\n",
    "print(\"Centroids:\\n\",centroids)\n",
    "# assign each sample to a cluster\n",
    "clx,_ = vq(data,centroids)\n",
    "print(\"Cluster:\\n\",clx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete Cosine Transform\n",
    "from scipy.fftpack import dct\n",
    "print (\"DCT:\\n\",dct(np.array([4., 3., 5., 10., 5., 3.])))\n",
    "\n",
    "#Inverse Discrete Cosine Transform\n",
    "from scipy.fftpack import idct\n",
    "print(\"IDCT:\\n\",idct(np.array([4., 3., 5., 10., 5., 3.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy - Integrate¶\n",
    "\n",
    "The general form of quad is scipy.integrate.quad(f, a, b), Where ‘f’ is the name of the function to be integrated. Whereas, ‘a’ and ‘b’ are the lower and upper limits, respectively. Let us see an example of the Gaussian function, integrated over a range of 0 and 1.\n",
    "\n",
    "∫f(x)dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Integration \n",
    "import scipy.integrate\n",
    "from numpy import exp\n",
    "f= lambda x:exp(-x**2)\n",
    "i = scipy.integrate.quad(f, 0, 1)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear Algebra\n",
    "x + 3y + 5z = 10\n",
    "2x + 5y + z = 8¶ \n",
    "2x + 3y + 8z = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the scipy and numpy packages\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "#Declaring the numpy arrays\n",
    "a = np.array([[1, 3, 5], [2, 5, 1], [2, 3, 8]])\n",
    "b = np.array([10, 8, 3])\n",
    "\n",
    "#Passing the values to the solve function\n",
    "X = linalg.solve(a, b)\n",
    "\n",
    "#printing the result array\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a Determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the scipy and numpy packages\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "#Declaring the numpy array\n",
    "A = np.array([[1,2],[3,4]])\n",
    "\n",
    "#Passing the values to the det function\n",
    "x = linalg.det(A)\n",
    "\n",
    "#printing the result\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing the scipy and numpy packages\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "#Declaring the numpy array\n",
    "A = np.array([[1,2],[3,4]])\n",
    "\n",
    "#Passing the values to the eig function\n",
    "l, v = linalg.eig(A)\n",
    "\n",
    "#printing the result for eigen values\n",
    "print (\"Eigen Values :\\n\",l)\n",
    "\n",
    "#printing the result for eigen vectors\n",
    "print (\"Eigen Vectors:\\n\",v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "f = misc.face()\n",
    "misc.imsave('face.png', f) # uses the Image module (PIL)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Information of the image \n",
    "from scipy import misc\n",
    "face = misc.face(gray = False)\n",
    "print(face.mean(), face.max(), face.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping\n",
    "from scipy import misc\n",
    "face = misc.face(gray = True)\n",
    "lx,ly = face.shape\n",
    "# Cropping\n",
    "crop_face = face[lx//4 : -lx//4 , ly//4 : -ly//4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(crop_face)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up <-> down flip\n",
    "from scipy import misc\n",
    "face = misc.face()\n",
    "flip_ud_face = np.flipud(face)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(flip_ud_face)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotation\n",
    "from scipy import misc,ndimage\n",
    "face = misc.face()\n",
    "rotate_face = ndimage.rotate(face, 45)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(rotate_face)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurring \n",
    "from scipy import misc\n",
    "face = misc.face()\n",
    "blurred_face = ndimage.gaussian_filter(face, sigma=3)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(blurred_face)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Detection\n",
    "import scipy.ndimage as nd\n",
    "import numpy as np\n",
    "\n",
    "im = np.zeros((256, 256))\n",
    "im[64:-64, 64:-64] = 1\n",
    "im[90:-90,90:-90] = 2\n",
    "im = ndimage.gaussian_filter(im, 0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "img=mpimg.imread('C:/Users/thyagaragu/Desktop/Data/Image/C1.jpg')\n",
    "#print(img)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides a range of supervised and unsupervised learning algorithms via a consistent interface in Python.It is licensed under a permissive simplified BSD license and is distributed under many Linux distributions, encouraging academic and commercial use. The library is built upon the SciPy (Scientific Python) that must be installed before you can use scikit-learn. This stack that includes: NumPy: Base n-dimensional array package SciPy: Fundamental library for scientific computing Matplotlib: Comprehensive 2D/3D plotting IPython: Enhanced interactive console Sympy: Symbolic mathematics Pandas: Data structures and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sets available in sklearn\n",
    "iris= datasets.load_iris()\n",
    "houseprice = datasets.load_boston()\n",
    "diabetes = datasets.load_diabetes()\n",
    "digits = datasets.load_digits()\n",
    "linerud= datasets.load_linnerud()   #Fitness Club Data Set\n",
    "wine = datasets.load_wine()\n",
    "breastcancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.target_names)\n",
    "print(digits.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(houseprice.feature_names)\n",
    "print(houseprice.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes.feature_names)\n",
    "print(diabetes.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linerud.data[0])\n",
    "print(linerud.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wine.feature_names)\n",
    "print(wine.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(breastcancer.feature_names)\n",
    "print(breastcancer.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print shape of data to confirm data is loaded\n",
    "print(\"IRIS:\\n\",iris.data.shape)\n",
    "print(\"HOUSEPRICE:\\n\",houseprice.data.shape)\n",
    "print(\"DIABETES:\\n\",diabetes.data.shape)\n",
    "print(\"DIGITS:\\n\",digits.data.shape)\n",
    "print(\"LINERUD:\\n\",linerud.data.shape)\n",
    "print(\"WINE:\\n\",wine.data.shape)\n",
    "print(\"BREASTCANCER:\\n\",breastcancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what’s available in iris:\n",
    "iris.keys()\n",
    "print(\"IRIS KEYS:\\n\",iris.keys())\n",
    "n_samples, n_features = iris.data.shape\n",
    "print (\"IRIS # SAMPLES:\\n\",n_samples)\n",
    "print (\"IRIS # FEATURES:\\n\",n_features)\n",
    "print (\"IRIS FIRST FEW ROWS:\\n\",iris.data[0:10])\n",
    "print(\"IRIS TARGETS NAMES\",iris.target_names)\n",
    "print(\"IRIS FEATURE NAMES\",iris.feature_names)\n",
    "print(\"IRIS TARGET\",iris.target)\n",
    "print(\"IRIS DESCR\",iris.DESCR)\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "np.unique(iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split iris data in train and test data\n",
    "# A random permutation, to split the data randomly\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test = iris_X[indices[-10:]]\n",
    "iris_y_test = iris_y[indices[-10:]]\n",
    "# Create and fit a nearest-neighbor classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_X_train, iris_y_train)\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "weights='uniform')\n",
    "print(\"Predicted :\\n\",knn.predict(iris_X_test))\n",
    "print(\"Actual:\\n\",iris_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "LinearRegression, in its simplest form, fits a linear model to the data set by adjusting a set of parameters in order to make the sum of the squared residuals of the model as small as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X_train = diabetes.data[:-20]\n",
    "diabetes_X_test = diabetes.data[-20:]\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "print(\"Regression Coef:\\n\",regr.coef_)\n",
    "print(\"Mean:\\n\",np.mean((regr.predict(diabetes_X_test)-diabetes_y_test)**2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "# and 0 means that there is no linear relationship\n",
    "# between X and y.\n",
    "regr.score(diabetes_X_test, diabetes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample Decision Tree Classifier\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
